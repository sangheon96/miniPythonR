{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sang Heon Lee\n",
    "\n",
    "ID: 20581451\n",
    "\n",
    "Uwaterloo ID: sh68lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('image_train_Kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('image_test_Kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = data_train.label\n",
    "data_train = data_train.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       5       0   \n",
       "3           0       0       0       1       2       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       0       0       0       0       0       0       0       0       0   \n",
       "59996       0       0       0       0       0       0       0       0       0   \n",
       "59997       0       0       0       0       0       0       0       0       0   \n",
       "59998       0       0       0       0       0       0       0       0       0   \n",
       "59999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         0         0   \n",
       "2            0  ...         0         0         0        30        43   \n",
       "3            0  ...         3         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "59995        0  ...         0         0         0         0         0   \n",
       "59996        0  ...        73         0         0         0         0   \n",
       "59997        0  ...       160       162       163       135        94   \n",
       "59998        0  ...         0         0         0         0         0   \n",
       "59999        0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = data_test.ID\n",
    "data_test = data_test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.reshape(60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(data_test[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train / 255.0\n",
    "\n",
    "data_test = data_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.asarray(data_train)\n",
    "label_train = np.asarray(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_train, label_train, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[label_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first initial model\n",
    "model01 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second model\n",
    "model02 = Sequential()\n",
    "model02.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model02.add(MaxPooling2D((2, 2)))\n",
    "model02.add(Dropout(0.25))\n",
    "\n",
    "model02.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model02.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model02.add(Dropout(0.25))\n",
    "\n",
    "model02.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model02.add(Flatten())\n",
    "\n",
    "model02.add(Dense(128, activation='relu'))\n",
    "model02.add(Dropout(0.25))\n",
    "model02.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third model\n",
    "model03 = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "               input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.20),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),        \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.30),        \n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),    \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.40),        \n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.30),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.20),\n",
    "        \n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "adam = Adam(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with dropout and L2 regularizer\n",
    "model04 = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer='l2',\n",
    "               input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.20),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),        \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.30),        \n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),    \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.40),        \n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(1024, activation='relu', kernel_regularizer='l2'),\n",
    "        Dropout(0.30),\n",
    "        \n",
    "        Dense(512, activation='relu', kernel_regularizer='l2'),\n",
    "        Dropout(0.20),\n",
    "        \n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check the summary of model\n",
    "model02.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 11, 11, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,940,938\n",
      "Trainable params: 1,939,146\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model03.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 11, 11, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,940,938\n",
      "Trainable params: 1,939,146\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model04.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model01.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model02.compile(optimizer=adam,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model03.compile(optimizer=adam,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model04.compile(optimizer=adam,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 1.7585 - accuracy: 0.7076\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6823 - accuracy: 0.7833\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6612 - accuracy: 0.8038\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6481 - accuracy: 0.8167\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.6381 - accuracy: 0.8266\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.6319 - accuracy: 0.8324\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.6261 - accuracy: 0.8381\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6210 - accuracy: 0.8426\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6169 - accuracy: 0.8459\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6132 - accuracy: 0.8498\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6099 - accuracy: 0.8531\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6057 - accuracy: 0.8576\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6023 - accuracy: 0.8615\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6005 - accuracy: 0.8627\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5973 - accuracy: 0.8658\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5951 - accuracy: 0.8675\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5915 - accuracy: 0.8717\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5912 - accuracy: 0.8712\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5890 - accuracy: 0.8740\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5875 - accuracy: 0.8753\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5855 - accuracy: 0.8778\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5836 - accuracy: 0.8795\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5818 - accuracy: 0.8804\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5799 - accuracy: 0.8832\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5793 - accuracy: 0.8838\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5782 - accuracy: 0.8848s - loss: 1.5777 - ac\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5760 - accuracy: 0.8869\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5739 - accuracy: 0.8893\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5739 - accuracy: 0.8889\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5728 - accuracy: 0.8896\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5720 - accuracy: 0.8914\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5699 - accuracy: 0.8931\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5699 - accuracy: 0.8925\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5686 - accuracy: 0.8941\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5672 - accuracy: 0.8956\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5674 - accuracy: 0.8951\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5660 - accuracy: 0.8964\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5646 - accuracy: 0.8977\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5645 - accuracy: 0.8977\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5626 - accuracy: 0.9001\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5625 - accuracy: 0.9002\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5615 - accuracy: 0.9008\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5605 - accuracy: 0.9021\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5608 - accuracy: 0.9016\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5585 - accuracy: 0.9044\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5581 - accuracy: 0.9046\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5582 - accuracy: 0.9045\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5570 - accuracy: 0.9057\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5564 - accuracy: 0.9065\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5560 - accuracy: 0.9066\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5560 - accuracy: 0.9066\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5546 - accuracy: 0.9083\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5543 - accuracy: 0.9082\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5537 - accuracy: 0.9091\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5520 - accuracy: 0.9108\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5525 - accuracy: 0.9101\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5520 - accuracy: 0.9102\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5509 - accuracy: 0.9116\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5516 - accuracy: 0.9106\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5510 - accuracy: 0.9113\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5495 - accuracy: 0.9132\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5503 - accuracy: 0.9123\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5484 - accuracy: 0.9141\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5489 - accuracy: 0.9134\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5468 - accuracy: 0.9156\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5474 - accuracy: 0.9151\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5465 - accuracy: 0.9162\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5462 - accuracy: 0.9161\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5463 - accuracy: 0.9162\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5449 - accuracy: 0.9174\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5456 - accuracy: 0.9171\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5444 - accuracy: 0.9183\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5446 - accuracy: 0.9180\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5441 - accuracy: 0.9186\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5433 - accuracy: 0.9193\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5427 - accuracy: 0.9200\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5428 - accuracy: 0.9197\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5413 - accuracy: 0.9211\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5421 - accuracy: 0.9203\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5404 - accuracy: 0.9222\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5412 - accuracy: 0.9218\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5409 - accuracy: 0.9216\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5400 - accuracy: 0.9224\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5397 - accuracy: 0.9230\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5396 - accuracy: 0.9229\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5379 - accuracy: 0.9243\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5390 - accuracy: 0.9235\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5381 - accuracy: 0.9240\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5378 - accuracy: 0.9247\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5391 - accuracy: 0.9232\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5379 - accuracy: 0.9252\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5372 - accuracy: 0.9252\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5362 - accuracy: 0.9266\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5361 - accuracy: 0.9263\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5358 - accuracy: 0.9267\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5367 - accuracy: 0.9254\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5358 - accuracy: 0.9268\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5356 - accuracy: 0.9268\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5350 - accuracy: 0.9278\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5353 - accuracy: 0.9269\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5346 - accuracy: 0.9284\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5343 - accuracy: 0.9282\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5336 - accuracy: 0.9285\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5347 - accuracy: 0.9276\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5331 - accuracy: 0.9296\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5329 - accuracy: 0.9295\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5333 - accuracy: 0.9291\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5324 - accuracy: 0.9301\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5328 - accuracy: 0.9294\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5318 - accuracy: 0.9305\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5316 - accuracy: 0.9306\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5323 - accuracy: 0.9304\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5308 - accuracy: 0.9320\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5314 - accuracy: 0.9312\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5306 - accuracy: 0.9319\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5299 - accuracy: 0.9327\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5298 - accuracy: 0.9325\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5306 - accuracy: 0.9316\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5305 - accuracy: 0.9321\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5295 - accuracy: 0.9332\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5290 - accuracy: 0.9335\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5278 - accuracy: 0.9358\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5278 - accuracy: 0.9348\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5280 - accuracy: 0.9344\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5281 - accuracy: 0.9348\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5269 - accuracy: 0.9359\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5275 - accuracy: 0.9350\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5271 - accuracy: 0.9349\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5270 - accuracy: 0.9357\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5267 - accuracy: 0.9360\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5270 - accuracy: 0.9352\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5269 - accuracy: 0.9354\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5257 - accuracy: 0.9366\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5270 - accuracy: 0.9354\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5255 - accuracy: 0.9369\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5255 - accuracy: 0.9370\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5260 - accuracy: 0.9363\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5255 - accuracy: 0.9367\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5253 - accuracy: 0.9374\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5247 - accuracy: 0.9378\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5240 - accuracy: 0.9383\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5241 - accuracy: 0.9385\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5240 - accuracy: 0.9386\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5239 - accuracy: 0.9383\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5240 - accuracy: 0.9385\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5240 - accuracy: 0.9385\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5234 - accuracy: 0.9391\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5232 - accuracy: 0.9389\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5229 - accuracy: 0.9391\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5226 - accuracy: 0.9399\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5235 - accuracy: 0.9391\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5229 - accuracy: 0.9398\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5223 - accuracy: 0.9404\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5230 - accuracy: 0.9395\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5221 - accuracy: 0.9403\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5218 - accuracy: 0.9405\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5215 - accuracy: 0.9410\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5212 - accuracy: 0.9416\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5217 - accuracy: 0.9406\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5215 - accuracy: 0.9411\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5211 - accuracy: 0.9415\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5208 - accuracy: 0.9415\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5208 - accuracy: 0.9415\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5205 - accuracy: 0.9421\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1.5198 - accuracy: 0.9426\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.5207 - accuracy: 0.9419\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5201 - accuracy: 0.9423\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5188 - accuracy: 0.9438\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5187 - accuracy: 0.9434\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5193 - accuracy: 0.9430\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5199 - accuracy: 0.9425\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5200 - accuracy: 0.9422\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5198 - accuracy: 0.9427\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5189 - accuracy: 0.9432\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5193 - accuracy: 0.9433\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5189 - accuracy: 0.9432\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5193 - accuracy: 0.9432\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5180 - accuracy: 0.9444\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.5174 - accuracy: 0.9449\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5185 - accuracy: 0.9439\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5173 - accuracy: 0.9452\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5174 - accuracy: 0.9447\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.5164 - accuracy: 0.9462\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5171 - accuracy: 0.9457\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5169 - accuracy: 0.9457\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5175 - accuracy: 0.9448\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5159 - accuracy: 0.9469\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5165 - accuracy: 0.9459\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5168 - accuracy: 0.9453\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5162 - accuracy: 0.9464\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 1.5155 - accuracy: 0.9468\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5157 - accuracy: 0.9464\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5159 - accuracy: 0.9463\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1.5163 - accuracy: 0.9463\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5158 - accuracy: 0.9463\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5156 - accuracy: 0.9469\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5151 - accuracy: 0.9472\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5158 - accuracy: 0.9464\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5147 - accuracy: 0.9477\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5155 - accuracy: 0.9468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162f458a988>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result 10\n",
    "model02.fit(data_train, label_train, batch_size=64, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model3 hyperparameters setting and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4853 - accuracy: 0.9759\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4863 - accuracy: 0.9748\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4870 - accuracy: 0.9742\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4868 - accuracy: 0.9743\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4870 - accuracy: 0.9741\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4868 - accuracy: 0.9743\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4862 - accuracy: 0.9749\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4865 - accuracy: 0.9747\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4877 - accuracy: 0.9735\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4860 - accuracy: 0.9752\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4862 - accuracy: 0.9748\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4861 - accuracy: 0.9749\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4854 - accuracy: 0.9756\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4889 - accuracy: 0.9723\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4863 - accuracy: 0.9747\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4865 - accuracy: 0.9745\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4862 - accuracy: 0.9748\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4852 - accuracy: 0.9759\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4865 - accuracy: 0.9746\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4859 - accuracy: 0.9753\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4871 - accuracy: 0.9740\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4849 - accuracy: 0.9761\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4869 - accuracy: 0.9742\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4859 - accuracy: 0.9752\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4850 - accuracy: 0.9761\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4860 - accuracy: 0.9751\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4864 - accuracy: 0.9748\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4869 - accuracy: 0.9742\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4855 - accuracy: 0.9757\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4877 - accuracy: 0.9733\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4866 - accuracy: 0.9746\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4857 - accuracy: 0.9754\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4856 - accuracy: 0.9754\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4870 - accuracy: 0.9740\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4872 - accuracy: 0.9739\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4870 - accuracy: 0.9740\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4860 - accuracy: 0.9751\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4880 - accuracy: 0.9730\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4859 - accuracy: 0.9752\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4870 - accuracy: 0.9741 - loss: 1.4870 - accuracy: 0.97\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4858 - accuracy: 0.9752\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4853 - accuracy: 0.9760\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4858 - accuracy: 0.9754\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4863 - accuracy: 0.9748\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4870 - accuracy: 0.9742\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4857 - accuracy: 0.9754 - loss: 1.4856 - accuracy\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4862 - accuracy: 0.9750\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4861 - accuracy: 0.9751\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4862 - accuracy: 0.9750\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4850 - accuracy: 0.9760\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4852 - accuracy: 0.9760\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4874 - accuracy: 0.9737\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4846 - accuracy: 0.9764 - loss: 1.4847 - ac\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4846 - accuracy: 0.9765\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4842 - accuracy: 0.9769\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4857 - accuracy: 0.9754\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4867 - accuracy: 0.9743\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4860 - accuracy: 0.9750\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4845 - accuracy: 0.9765\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4847 - accuracy: 0.9764\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4847 - accuracy: 0.9765\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4851 - accuracy: 0.9760\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4863 - accuracy: 0.9748\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4850 - accuracy: 0.9760\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4849 - accuracy: 0.9762\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4842 - accuracy: 0.9770\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4856 - accuracy: 0.9754\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4846 - accuracy: 0.9765\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4855 - accuracy: 0.9755\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4842 - accuracy: 0.9769\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4849 - accuracy: 0.9762\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4850 - accuracy: 0.9762\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4864 - accuracy: 0.9747\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4858 - accuracy: 0.9753\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4860 - accuracy: 0.9750\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4855 - accuracy: 0.9756\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4852 - accuracy: 0.9760\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4845 - accuracy: 0.9766\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4847 - accuracy: 0.9764\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4835 - accuracy: 0.9776\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4851 - accuracy: 0.9760\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4837 - accuracy: 0.9774 - loss: 1.4836 - \n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4854 - accuracy: 0.9757\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4858 - accuracy: 0.9753\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4845 - accuracy: 0.9767\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4839 - accuracy: 0.9772 - loss: 1.4840 - accuracy\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4849 - accuracy: 0.9762\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4835 - accuracy: 0.9776\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4846 - accuracy: 0.9765\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4859 - accuracy: 0.9752\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4857 - accuracy: 0.9754\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4849 - accuracy: 0.9762\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4847 - accuracy: 0.9764\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4840 - accuracy: 0.9771\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4846 - accuracy: 0.9765\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4844 - accuracy: 0.9766\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4844 - accuracy: 0.9767 - l - ETA: \n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4837 - accuracy: 0.9773\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4851 - accuracy: 0.9760\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4844 - accuracy: 0.9767\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4845 - accuracy: 0.9766\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4847 - accuracy: 0.9764\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4840 - accuracy: 0.9771\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4848 - accuracy: 0.9764\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4849 - accuracy: 0.9762\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4830 - accuracy: 0.9782\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4836 - accuracy: 0.9775\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4838 - accuracy: 0.9774\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4848 - accuracy: 0.9763\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4844 - accuracy: 0.9768\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4837 - accuracy: 0.9775\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4835 - accuracy: 0.9776\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4818 - accuracy: 0.9793\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4834 - accuracy: 0.9777 - loss: 1.4832 - ac\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4844 - accuracy: 0.9767\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4828 - accuracy: 0.9784\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4832 - accuracy: 0.9779 - loss: 1.4834 - accura\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4837 - accuracy: 0.9774\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4837 - accuracy: 0.9774\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4829 - accuracy: 0.9782\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4836 - accuracy: 0.9775\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4832 - accuracy: 0.9780\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4873 - accuracy: 0.9739\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4845 - accuracy: 0.9766\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4836 - accuracy: 0.9775\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4825 - accuracy: 0.9786\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4823 - accuracy: 0.9787\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4830 - accuracy: 0.9781\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4824 - accuracy: 0.9788\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4834 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fe1d1fc8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result 08\n",
    "model03.fit(data_train, label_train, batch_size=128, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4823 - accuracy: 0.9788\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4822 - accuracy: 0.9790\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4837 - accuracy: 0.9774\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4834 - accuracy: 0.9777\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4829 - accuracy: 0.9783 - loss: 1.4830 - accuracy: \n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4829 - accuracy: 0.9783\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4832 - accuracy: 0.9779\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4844 - accuracy: 0.9768\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4840 - accuracy: 0.9771\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4833 - accuracy: 0.9779\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4844 - accuracy: 0.9768\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4829 - accuracy: 0.9783\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4820 - accuracy: 0.9791\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4843 - accuracy: 0.9768\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4853 - accuracy: 0.9758\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4850 - accuracy: 0.9761\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4846 - accuracy: 0.9765\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4844 - accuracy: 0.9766\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 1.4834 - accuracy: 0.9777\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 1.4837 - accuracy: 0.9775\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 1.4822 - accuracy: 0.9790\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4826 - accuracy: 0.9785\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4835 - accuracy: 0.9775\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4830 - accuracy: 0.9781\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4826 - accuracy: 0.9784\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4828 - accuracy: 0.9784\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4826 - accuracy: 0.9785\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4824 - accuracy: 0.9787\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4822 - accuracy: 0.9790\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4830 - accuracy: 0.9781\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4834 - accuracy: 0.9777\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4829 - accuracy: 0.9783\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4831 - accuracy: 0.9780\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4824 - accuracy: 0.9787\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4827 - accuracy: 0.9783\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4825 - accuracy: 0.9787\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4824 - accuracy: 0.9786\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4821 - accuracy: 0.9791\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4826 - accuracy: 0.9786\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4827 - accuracy: 0.9784\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4833 - accuracy: 0.9779\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4848 - accuracy: 0.9764\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4833 - accuracy: 0.9778\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4813 - accuracy: 0.9798\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 1.4830 - accuracy: 0.9782\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4831 - accuracy: 0.9780\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4831 - accuracy: 0.9780\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4819 - accuracy: 0.9792\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4809 - accuracy: 0.9802\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4824 - accuracy: 0.9787\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4813 - accuracy: 0.9799\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4811 - accuracy: 0.9799\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4811 - accuracy: 0.9801\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4839 - accuracy: 0.9771\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4848 - accuracy: 0.9763\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4835 - accuracy: 0.9776\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 1.4840 - accuracy: 0.9771\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4833 - accuracy: 0.9779\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4826 - accuracy: 0.9786\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4829 - accuracy: 0.9782\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4819 - accuracy: 0.9791\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4820 - accuracy: 0.9791\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4825 - accuracy: 0.9786\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4817 - accuracy: 0.9794\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4823 - accuracy: 0.9788\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4830 - accuracy: 0.9782\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4807 - accuracy: 0.9805\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4820 - accuracy: 0.9791\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4825 - accuracy: 0.9785\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4833 - accuracy: 0.9779\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4839 - accuracy: 0.9772\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4832 - accuracy: 0.9779\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4826 - accuracy: 0.9786\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4815 - accuracy: 0.9796\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4820 - accuracy: 0.9791 - los\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4818 - accuracy: 0.9793\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4831 - accuracy: 0.9780\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4816 - accuracy: 0.9796\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4814 - accuracy: 0.9797\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4829 - accuracy: 0.9782\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 1.4840 - accuracy: 0.9771\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4809 - accuracy: 0.9803\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4800 - accuracy: 0.9812\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4818 - accuracy: 0.9793\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4825 - accuracy: 0.9785\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4814 - accuracy: 0.9797\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4819 - accuracy: 0.9792 - loss: 1.4820 - accuracy: 0.\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4810 - accuracy: 0.9801\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4828 - accuracy: 0.9783\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4817 - accuracy: 0.9794\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4848 - accuracy: 0.9764\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4827 - accuracy: 0.9785\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4823 - accuracy: 0.9788\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4814 - accuracy: 0.9797\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4812 - accuracy: 0.9800\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4822 - accuracy: 0.9789\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4833 - accuracy: 0.9778\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4819 - accuracy: 0.9792\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4811 - accuracy: 0.9800\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4820 - accuracy: 0.9791\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4823 - accuracy: 0.9789\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4806 - accuracy: 0.9806\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4807 - accuracy: 0.9805\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4810 - accuracy: 0.9801\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4796 - accuracy: 0.9816\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4814 - accuracy: 0.9797\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4812 - accuracy: 0.9799\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 1.4813 - accuracy: 0.9798\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4819 - accuracy: 0.9793\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 1.4810 - accuracy: 0.9802\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 1.4807 - accuracy: 0.9805\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4812 - accuracy: 0.9798\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 1.4808 - accuracy: 0.9803\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 1.4804 - accuracy: 0.9807\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4808 - accuracy: 0.9803\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4818 - accuracy: 0.9793\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4829 - accuracy: 0.9783\n",
      "Epoch 147/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4813 - accuracy: 0.9798 - loss: 1.4812 \n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4799 - accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fe25a748>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4811 - accuracy: 0.9801\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4810 - accuracy: 0.9802\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4801 - accuracy: 0.9811\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4819 - accuracy: 0.9793\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4810 - accuracy: 0.9802\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4817 - accuracy: 0.9794\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4820 - accuracy: 0.9790\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4809 - accuracy: 0.9802\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.97 - 7s 119us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4816 - accuracy: 0.9795\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4801 - accuracy: 0.9811\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4811 - accuracy: 0.9800\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4811 - accuracy: 0.9801\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4808 - accuracy: 0.9803\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4820 - accuracy: 0.9791\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4815 - accuracy: 0.9797\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4821 - accuracy: 0.9790\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4809 - accuracy: 0.9803\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4794 - accuracy: 0.9817\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4801 - accuracy: 0.9810\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4794 - accuracy: 0.9817\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4817 - accuracy: 0.9795\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4822 - accuracy: 0.9790\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4810 - accuracy: 0.9801\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4799 - accuracy: 0.9813\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4792 - accuracy: 0.9820\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4802 - accuracy: 0.9809\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4793 - accuracy: 0.9819\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4795 - accuracy: 0.9816 - los\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4799 - accuracy: 0.9813\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4815 - accuracy: 0.9796\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4811 - accuracy: 0.9801\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4812 - accuracy: 0.9798\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4800 - accuracy: 0.9812\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4808 - accuracy: 0.9803\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4807 - accuracy: 0.9804\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 1.4804 - accuracy: 0.9807\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4819 - accuracy: 0.9792\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4814 - accuracy: 0.9797\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4801 - accuracy: 0.9811\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4809 - accuracy: 0.9803\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4812 - accuracy: 0.9799\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4804 - accuracy: 0.9807\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4808 - accuracy: 0.9803\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4809 - accuracy: 0.9803\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4792 - accuracy: 0.9820\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4807 - accuracy: 0.9804\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4798 - accuracy: 0.9814\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4799 - accuracy: 0.9811\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4802 - accuracy: 0.9809\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4802 - accuracy: 0.9810 -\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4804 - accuracy: 0.9807\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4819 - accuracy: 0.9793\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4808 - accuracy: 0.9804\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4802 - accuracy: 0.9809\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4798 - accuracy: 0.9812\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4798 - accuracy: 0.9813 - loss: 1.4798 - accuracy: 0.98\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4803 - accuracy: 0.9808\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4797 - accuracy: 0.9815\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4793 - accuracy: 0.9818\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4784 - accuracy: 0.9828\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4791 - accuracy: 0.9820\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4803 - accuracy: 0.9809\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4790 - accuracy: 0.9821\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4787 - accuracy: 0.9825\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4793 - accuracy: 0.9819\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4795 - accuracy: 0.9817\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4784 - accuracy: 0.9828\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4795 - accuracy: 0.9817\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4799 - accuracy: 0.9812\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4810 - accuracy: 0.9801\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4799 - accuracy: 0.9813\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4789 - accuracy: 0.9822\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4801 - accuracy: 0.9810\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4797 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fe2b3ac8>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4804 - accuracy: 0.9808\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4805 - accuracy: 0.9807\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4794 - accuracy: 0.9818 - loss: 1.4792 - accuracy\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4799 - accuracy: 0.9813\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4797 - accuracy: 0.9814\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4802 - accuracy: 0.9810\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4802 - accuracy: 0.9809\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4804 - accuracy: 0.9807\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4798 - accuracy: 0.9814\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4793 - accuracy: 0.9819 - loss: 1.4795 - accu\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4791 - accuracy: 0.9820\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.98 - 7s 120us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4784 - accuracy: 0.9828\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4783 - accuracy: 0.9828\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4786 - accuracy: 0.9824\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4788 - accuracy: 0.9824\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4804 - accuracy: 0.9808\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4806 - accuracy: 0.9805\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4797 - accuracy: 0.9815\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4794 - accuracy: 0.9818\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4789 - accuracy: 0.9823\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4783 - accuracy: 0.9829\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4778 - accuracy: 0.9833 - loss:\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4785 - accuracy: 0.9827\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4787 - accuracy: 0.9825\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4809 - accuracy: 0.9802\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4789 - accuracy: 0.9823\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4783 - accuracy: 0.9829\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4776 - accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4788 - accuracy: 0.9824\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4776 - accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4790 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4782 - accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4782 - accuracy: 0.9829\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4784 - accuracy: 0.9828\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4794 - accuracy: 0.9817\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4778 - accuracy: 0.9834\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4784 - accuracy: 0.9826\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4800 - accuracy: 0.9811\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4790 - accuracy: 0.9821\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4777 - accuracy: 0.9835\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4782 - accuracy: 0.9829\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4784 - accuracy: 0.9828\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4789 - accuracy: 0.9823\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4805 - accuracy: 0.9806\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4789 - accuracy: 0.9823\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4804 - accuracy: 0.9808\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4783 - accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fe2cd948>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4790 - accuracy: 0.9821\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4776 - accuracy: 0.9836\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4781 - accuracy: 0.9831\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4788 - accuracy: 0.9824\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4782 - accuracy: 0.9829\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4785 - accuracy: 0.9827\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4774 - accuracy: 0.9838\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4777 - accuracy: 0.9835\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4781 - accuracy: 0.9831\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4794 - accuracy: 0.9816\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4781 - accuracy: 0.9831\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4776 - accuracy: 0.9836\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4779 - accuracy: 0.9833 - loss: 1.4778 - accu\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4807 - accuracy: 0.9804\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4776 - accuracy: 0.9836\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4791 - accuracy: 0.9820\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4788 - accuracy: 0.9824\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4793 - accuracy: 0.9818\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4785 - accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4796 - accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4783 - accuracy: 0.9829\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4781 - accuracy: 0.9830 - loss: 1.4781 - accura\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4778 - accuracy: 0.9834\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4774 - accuracy: 0.9838\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4789 - accuracy: 0.9823\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4786 - accuracy: 0.9826\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4791 - accuracy: 0.9821\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4783 - accuracy: 0.9829\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4789 - accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4772 - accuracy: 0.9840\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4788 - accuracy: 0.9823\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4769 - accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4777 - accuracy: 0.9835\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4770 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4773 - accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fe262c88>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4791 - accuracy: 0.9820\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4773 - accuracy: 0.9838\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4765 - accuracy: 0.9847\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4779 - accuracy: 0.9832\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4786 - accuracy: 0.9825\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4787 - accuracy: 0.9824\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4776 - accuracy: 0.9836\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4771 - accuracy: 0.9841\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4760 - accuracy: 0.9852\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4777 - accuracy: 0.9835\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4785 - accuracy: 0.9826\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4784 - accuracy: 0.9827\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4781 - accuracy: 0.9830\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4770 - accuracy: 0.9841 - loss: 1.4771 - accuracy - ETA: 0s -\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4790 - accuracy: 0.9822\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4769 - accuracy: 0.9844\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4796 - accuracy: 0.9816\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4792 - accuracy: 0.9819\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4783 - accuracy: 0.9828\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4795 - accuracy: 0.9816\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4777 - accuracy: 0.9834\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4763 - accuracy: 0.9849\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4782 - accuracy: 0.9830\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4776 - accuracy: 0.9835\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4776 - accuracy: 0.9835\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4772 - accuracy: 0.9840\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4763 - accuracy: 0.9849\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4765 - accuracy: 0.9847\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4761 - accuracy: 0.9850\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4758 - accuracy: 0.9854\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4779 - accuracy: 0.9833\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4766 - accuracy: 0.9846\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4772 - accuracy: 0.9839\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4759 - accuracy: 0.9852 - loss: 1.4758 - accura\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4771 - accuracy: 0.9841\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4773 - accuracy: 0.9838\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4774 - accuracy: 0.9838\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 8s 135us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4760 - accuracy: 0.9852\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4755 - accuracy: 0.9857\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 1.4765 - accuracy: 0.9847\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4782 - accuracy: 0.9828\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4778 - accuracy: 0.9833\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4763 - accuracy: 0.9849\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4766 - accuracy: 0.9846\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4769 - accuracy: 0.9842\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4774 - accuracy: 0.9837\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4772 - accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4753 - accuracy: 0.9859\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4755 - accuracy: 0.9856\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4755 - accuracy: 0.9857\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4774 - accuracy: 0.9838\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4778 - accuracy: 0.9834\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4776 - accuracy: 0.9835\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4790 - accuracy: 0.9821 - l - ETA: 0s - loss:\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4763 - accuracy: 0.9849\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4761 - accuracy: 0.9850\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4773 - accuracy: 0.9839\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4773 - accuracy: 0.9838\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4749 - accuracy: 0.9863\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4753 - accuracy: 0.9858\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4746 - accuracy: 0.9865\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4775 - accuracy: 0.9837\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4757 - accuracy: 0.9855\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4761 - accuracy: 0.9850\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4761 - accuracy: 0.9850\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4768 - accuracy: 0.9844\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4764 - accuracy: 0.9848\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4754 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fc7e5688>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4774 - accuracy: 0.9838\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4776 - accuracy: 0.9835\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 1.4755 - accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.4753 - accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4756 - accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4759 - accuracy: 0.9853\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4748 - accuracy: 0.9864\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4756 - accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4761 - accuracy: 0.9850\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4759 - accuracy: 0.9853\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4759 - accuracy: 0.9853\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4753 - accuracy: 0.9859\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4767 - accuracy: 0.9844\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4764 - accuracy: 0.9848\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4750 - accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4748 - accuracy: 0.9863\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4769 - accuracy: 0.9843\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4780 - accuracy: 0.9831\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4753 - accuracy: 0.9858\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4750 - accuracy: 0.9862\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4761 - accuracy: 0.9851\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4748 - accuracy: 0.9863\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4762 - accuracy: 0.9849\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4770 - accuracy: 0.9841\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 1.4753 - accuracy: 0.9858\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4767 - accuracy: 0.9844 - loss: 1.476\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 1.4758 - accuracy: 0.9854\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4765 - accuracy: 0.9847\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4755 - accuracy: 0.9857\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4759 - accuracy: 0.9853\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4743 - accuracy: 0.9869\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4756 - accuracy: 0.9856\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4758 - accuracy: 0.9854\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4755 - accuracy: 0.9856\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4753 - accuracy: 0.9858\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4760 - accuracy: 0.9851\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4759 - accuracy: 0.9853\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4756 - accuracy: 0.9856 - loss: 1.4756 \n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4751 - accuracy: 0.9861 - loss: 1.4752 - accu\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4752 - accuracy: 0.9860\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 1.4765 - accuracy: 0.9846\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4746 - accuracy: 0.9865\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4764 - accuracy: 0.9847\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4753 - accuracy: 0.9858\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 1.4750 - accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4744 - accuracy: 0.9868\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4748 - accuracy: 0.9863\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4749 - accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4746 - accuracy: 0.9865\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1.4745 - accuracy: 0.9866\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 1.4765 - accuracy: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1630249d308>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(data_train, label_train, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result18\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_train, label_train, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.98 - 6s 129us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4749 - accuracy: 0.9863\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4773 - accuracy: 0.9838\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4770 - accuracy: 0.9842\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4764 - accuracy: 0.9848\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4766 - accuracy: 0.9845\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4751 - accuracy: 0.9860\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4745 - accuracy: 0.9866\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4771 - accuracy: 0.9839\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4768 - accuracy: 0.9843\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4743 - accuracy: 0.9868\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4770 - accuracy: 0.9842\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4749 - accuracy: 0.9863 - loss: 1.4748 - accuracy: 0.98\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4763 - accuracy: 0.9848\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4780 - accuracy: 0.9832\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4761 - accuracy: 0.9852\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4763 - accuracy: 0.9849\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4752 - accuracy: 0.9860\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4758 - accuracy: 0.9854\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4771 - accuracy: 0.9840\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4772 - accuracy: 0.9840\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4766 - accuracy: 0.9846\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 1.4754 - accuracy: 0.9857 - loss: 1\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4748 - accuracy: 0.9863\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4750 - accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4755 - accuracy: 0.9856\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4748 - accuracy: 0.9864\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4749 - accuracy: 0.9863\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4745 - accuracy: 0.9866\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4775 - accuracy: 0.9836\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4758 - accuracy: 0.9853\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4752 - accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4749 - accuracy: 0.9863\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4740 - accuracy: 0.9871\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4739 - accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4742 - accuracy: 0.9869\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9867\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4741 - accuracy: 0.9870\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.4743 - accuracy: 0.9869\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4749 - accuracy: 0.9863\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4742 - accuracy: 0.9869\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4746 - accuracy: 0.9865\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4744 - accuracy: 0.9867\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4748 - accuracy: 0.9863\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4752 - accuracy: 0.9860\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4746 - accuracy: 0.9865\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4749 - accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4762 - accuracy: 0.9850\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4756 - accuracy: 0.9855\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4754 - accuracy: 0.9857\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4758 - accuracy: 0.9854\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4757 - accuracy: 0.9854\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.4752 - accuracy: 0.9860\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4748 - accuracy: 0.9864\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 1.4739 - accuracy: 0.9873\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4747 - accuracy: 0.9865\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4744 - accuracy: 0.9868\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4741 - accuracy: 0.9870\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4743 - accuracy: 0.9869\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4759 - accuracy: 0.9852\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4751 - accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4736 - accuracy: 0.9875\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4750 - accuracy: 0.9861\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4752 - accuracy: 0.9859\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 1.4746 - accuracy: 0.9866\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 1.4754 - accuracy: 0.9858\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 1.4746 - accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161310649c8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result18\n",
    "model03.fit(X_train, y_train, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result19\n",
    "X_train19, X_val19, y_train19, y_val19 = train_test_split(data_train, label_train, test_size=0.15, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 9000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 1.4756 - accuracy: 0.9855 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4682 - val_accuracy: 0.9930\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9867 - val_loss: 1.4682 - val_accuracy: 0.9930\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4693 - val_accuracy: 0.9919\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4748 - accuracy: 0.9864 - val_loss: 1.4681 - val_accuracy: 0.9930\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4684 - val_accuracy: 0.9928\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4743 - accuracy: 0.9869 - val_loss: 1.4674 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4684 - val_accuracy: 0.9928\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4678 - val_accuracy: 0.9933\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4743 - accuracy: 0.9869 - val_loss: 1.4681 - val_accuracy: 0.9930\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4679 - val_accuracy: 0.9932\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4747 - accuracy: 0.9865 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4750 - accuracy: 0.9861 - val_loss: 1.4728 - val_accuracy: 0.9883\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4758 - accuracy: 0.9854 - val_loss: 1.4683 - val_accuracy: 0.9929\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4750 - accuracy: 0.9861 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4749 - accuracy: 0.9862 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4751 - accuracy: 0.9861 - val_loss: 1.4693 - val_accuracy: 0.9918\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9864 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4680 - val_accuracy: 0.9931\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4683 - val_accuracy: 0.9929\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4728 - val_accuracy: 0.9883\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4686 - val_accuracy: 0.9926\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4684 - val_accuracy: 0.9928\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4749 - accuracy: 0.9862 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4686 - val_accuracy: 0.9926\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4679 - val_accuracy: 0.9932\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4745 - accuracy: 0.9867 - val_loss: 1.4686 - val_accuracy: 0.9926\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4691 - val_accuracy: 0.9921\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4679 - val_accuracy: 0.9932\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4683 - val_accuracy: 0.9929\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4679 - val_accuracy: 0.9932\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4688 - val_accuracy: 0.9924\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9864 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4684 - val_accuracy: 0.9928\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4743 - accuracy: 0.9869 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4749 - accuracy: 0.9862 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4744 - accuracy: 0.9867 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4693 - val_accuracy: 0.9919\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4744 - accuracy: 0.9867 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4682 - val_accuracy: 0.9930\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9864 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4759 - accuracy: 0.9852 - val_loss: 1.4698 - val_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4742 - accuracy: 0.9869 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4745 - accuracy: 0.9867 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4751 - accuracy: 0.9860 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4684 - val_accuracy: 0.9928\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4682 - val_accuracy: 0.9930\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4753 - accuracy: 0.9858 - val_loss: 1.4680 - val_accuracy: 0.9931\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4682 - val_accuracy: 0.9930\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4746 - accuracy: 0.9866 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4750 - accuracy: 0.9861 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4744 - accuracy: 0.9867 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4687 - val_accuracy: 0.9924\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4686 - val_accuracy: 0.9926\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4750 - accuracy: 0.9862 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4685 - val_accuracy: 0.9927\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4691 - val_accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16136554e08>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result19\n",
    "model03.fit(X_train19, y_train19, batch_size=128, epochs=100, verbose=1, validation_data=(X_val19, y_val19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result20\n",
    "X_train20, X_val20, y_train20, y_val20 = train_test_split(data_train, label_train, test_size=0.3, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 18000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4691 - val_accuracy: 0.9921\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4693 - val_accuracy: 0.9918\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4693 - val_accuracy: 0.9918\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4752 - accuracy: 0.9860 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4694 - val_accuracy: 0.9918\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4743 - accuracy: 0.9868 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4746 - accuracy: 0.9866 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4694 - val_accuracy: 0.9918\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4742 - accuracy: 0.9869 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4749 - accuracy: 0.9862 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4689 - val_accuracy: 0.9923\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 1.4743 - accuracy: 0.9868 - val_loss: 1.4697 - val_accuracy: 0.9915\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4688 - val_accuracy: 0.9923\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4691 - val_accuracy: 0.9920\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4693 - val_accuracy: 0.9919\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4703 - val_accuracy: 0.99098 - ac\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4752 - accuracy: 0.9859 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4757 - accuracy: 0.9854 - val_loss: 1.4719 - val_accuracy: 0.9892\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 1.4742 - accuracy: 0.9869 - val_loss: 1.4697 - val_accuracy: 0.9915\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4693 - val_accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4695 - val_accuracy: 0.9916\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4690 - val_accuracy: 0.9921\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4696 - val_accuracy: 0.9915\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 1.4749 - accuracy: 0.9863 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 1.4751 - accuracy: 0.9861 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4720 - val_accuracy: 0.9892\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4694 - val_accuracy: 0.9918\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4692 - val_accuracy: 0.9919\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4697 - val_accuracy: 0.9915\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4695 - val_accuracy: 0.9916\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4745 - accuracy: 0.9866 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4746 - accuracy: 0.9865 - val_loss: 1.4719 - val_accuracy: 0.9892\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4708 - val_accuracy: 0.9904\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4748 - accuracy: 0.9863 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 1.4747 - accuracy: 0.9864 - val_loss: 1.4705 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16137b30f08>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result20\n",
    "model03.fit(X_train20, y_train20, batch_size=128, epochs=100, verbose=1, validation_data=(X_val20, y_val20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result21\n",
    "X_train21, X_val21, y_train21, y_val21 = train_test_split(data_train, label_train, test_size=0.27, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43799 samples, validate on 16201 samples\n",
      "Epoch 1/100\n",
      "43799/43799 [==============================] - 7s 156us/sample - loss: 1.4751 - accuracy: 0.9860 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 2/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4748 - accuracy: 0.9862 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 3/100\n",
      "43799/43799 [==============================] - 6s 142us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 4/100\n",
      "43799/43799 [==============================] - 6s 141us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 5/100\n",
      "43799/43799 [==============================] - 6s 142us/sample - loss: 1.4742 - accuracy: 0.9869 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 6/100\n",
      "43799/43799 [==============================] - 6s 141us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 7/100\n",
      "43799/43799 [==============================] - 6s 141us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 8/100\n",
      "43799/43799 [==============================] - 6s 142us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4740 - val_accuracy: 0.9871\n",
      "Epoch 9/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4750 - accuracy: 0.9861 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 11/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 12/100\n",
      "43799/43799 [==============================] - 6s 139us/sample - loss: 1.4743 - accuracy: 0.9868 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 13/100\n",
      "43799/43799 [==============================] - 6s 139us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 14/100\n",
      "43799/43799 [==============================] - 6s 136us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 15/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 16/100\n",
      "43799/43799 [==============================] - 6s 147us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "43799/43799 [==============================] - 6s 142us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4696 - val_accuracy: 0.9915\n",
      "Epoch 18/100\n",
      "43799/43799 [==============================] - 6s 142us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 19/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4694 - val_accuracy: 0.9917\n",
      "Epoch 20/100\n",
      "43799/43799 [==============================] - 7s 155us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4695 - val_accuracy: 0.9916\n",
      "Epoch 21/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4689 - val_accuracy: 0.9922\n",
      "Epoch 22/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4691 - val_accuracy: 0.9920\n",
      "Epoch 23/100\n",
      "43799/43799 [==============================] - 6s 139us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4694 - val_accuracy: 0.9918\n",
      "Epoch 24/100\n",
      "43799/43799 [==============================] - 7s 166us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4691 - val_accuracy: 0.9921\n",
      "Epoch 25/100\n",
      "43799/43799 [==============================] - 7s 155us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4690 - val_accuracy: 0.9922\n",
      "Epoch 26/100\n",
      "43799/43799 [==============================] - 7s 153us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 27/100\n",
      "43799/43799 [==============================] - 6s 147us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 28/100\n",
      "43799/43799 [==============================] - 6s 147us/sample - loss: 1.4725 - accuracy: 0.9887 - val_loss: 1.4693 - val_accuracy: 0.9919\n",
      "Epoch 29/100\n",
      "43799/43799 [==============================] - 7s 149us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 30/100\n",
      "43799/43799 [==============================] - 6s 148us/sample - loss: 1.4741 - accuracy: 0.9870 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 31/100\n",
      "43799/43799 [==============================] - 6s 148us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 32/100\n",
      "43799/43799 [==============================] - 6s 147us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 33/100\n",
      "43799/43799 [==============================] - 7s 150us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 34/100\n",
      "43799/43799 [==============================] - 8s 192us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 35/100\n",
      "43799/43799 [==============================] - 8s 179us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 36/100\n",
      "43799/43799 [==============================] - 7s 151us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 37/100\n",
      "43799/43799 [==============================] - 7s 150us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 38/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4692 - val_accuracy: 0.9920\n",
      "Epoch 39/100\n",
      "43799/43799 [==============================] - 7s 168us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 40/100\n",
      "43799/43799 [==============================] - 8s 181us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 41/100\n",
      "43799/43799 [==============================] - 8s 175us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 42/100\n",
      "43799/43799 [==============================] - 7s 159us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4695 - val_accuracy: 0.9917\n",
      "Epoch 43/100\n",
      "43799/43799 [==============================] - 7s 163us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "43799/43799 [==============================] - 8s 178us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 45/100\n",
      "43799/43799 [==============================] - 7s 158us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 46/100\n",
      "43799/43799 [==============================] - 7s 159us/sample - loss: 1.4750 - accuracy: 0.9861 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "43799/43799 [==============================] - 7s 157us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 48/100\n",
      "43799/43799 [==============================] - 7s 170us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 49/100\n",
      "43799/43799 [==============================] - 8s 177us/sample - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 50/100\n",
      "43799/43799 [==============================] - 7s 170us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "43799/43799 [==============================] - 7s 149us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 52/100\n",
      "43799/43799 [==============================] - 6s 148us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 53/100\n",
      "43799/43799 [==============================] - 7s 150us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 54/100\n",
      "43799/43799 [==============================] - 7s 151us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 55/100\n",
      "43799/43799 [==============================] - 7s 154us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 56/100\n",
      "43799/43799 [==============================] - 7s 153us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "43799/43799 [==============================] - 7s 150us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "43799/43799 [==============================] - 7s 153us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 59/100\n",
      "43799/43799 [==============================] - 6s 141us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 60/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 61/100\n",
      "43799/43799 [==============================] - 6s 148us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 62/100\n",
      "43799/43799 [==============================] - 7s 168us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 63/100\n",
      "43799/43799 [==============================] - 7s 169us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 64/100\n",
      "43799/43799 [==============================] - 7s 164us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4696 - val_accuracy: 0.9916\n",
      "Epoch 65/100\n",
      "43799/43799 [==============================] - 7s 152us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "43799/43799 [==============================] - 7s 150us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "43799/43799 [==============================] - 6s 143us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 68/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4738 - accuracy: 0.9874 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 69/100\n",
      "43799/43799 [==============================] - 6s 140us/sample - loss: 1.4743 - accuracy: 0.9868 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 70/100\n",
      "43799/43799 [==============================] - 7s 157us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "43799/43799 [==============================] - 7s 161us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 72/100\n",
      "43799/43799 [==============================] - 7s 167us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 73/100\n",
      "43799/43799 [==============================] - 7s 169us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 74/100\n",
      "43799/43799 [==============================] - 7s 158us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 75/100\n",
      "43799/43799 [==============================] - 6s 141us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 76/100\n",
      "43799/43799 [==============================] - 7s 155us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 77/100\n",
      "43799/43799 [==============================] - 7s 166us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 78/100\n",
      "43799/43799 [==============================] - 7s 169us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 79/100\n",
      "43799/43799 [==============================] - 7s 159us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "43799/43799 [==============================] - 7s 163us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 81/100\n",
      "43799/43799 [==============================] - 7s 156us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 82/100\n",
      "43799/43799 [==============================] - 6s 147us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 83/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 84/100\n",
      "43799/43799 [==============================] - 7s 169us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 85/100\n",
      "43799/43799 [==============================] - 7s 169us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 86/100\n",
      "43799/43799 [==============================] - 7s 168us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4700 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "43799/43799 [==============================] - 6s 138us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 89/100\n",
      "43799/43799 [==============================] - 7s 164us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 90/100\n",
      "43799/43799 [==============================] - 7s 156us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 91/100\n",
      "43799/43799 [==============================] - 6s 145us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 92/100\n",
      "43799/43799 [==============================] - 6s 138us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 93/100\n",
      "43799/43799 [==============================] - 6s 135us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 94/100\n",
      "43799/43799 [==============================] - 6s 136us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4698 - val_accuracy: 0.9914\n",
      "Epoch 95/100\n",
      "43799/43799 [==============================] - 6s 138us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 96/100\n",
      "43799/43799 [==============================] - 6s 135us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 97/100\n",
      "43799/43799 [==============================] - 6s 139us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 98/100\n",
      "43799/43799 [==============================] - 7s 149us/sample - loss: 1.4729 - accuracy: 0.9884 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 99/100\n",
      "43799/43799 [==============================] - 6s 145us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 100/100\n",
      "43799/43799 [==============================] - 6s 144us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4702 - val_accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16138f1a5c8>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result21\n",
    "model03.fit(X_train21, y_train21, batch_size=128, epochs=100, verbose=1, validation_data=(X_val21, y_val21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result22\n",
    "X_train22, X_val22, y_train22, y_val22 = train_test_split(data_train, label_train, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4740 - accuracy: 0.9871 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4708 - val_accuracy: 0.9904\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4721 - val_accuracy: 0.9890\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4743 - accuracy: 0.9869 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4732 - val_accuracy: 0.9879\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4708 - val_accuracy: 0.9904\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4743 - accuracy: 0.9868 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4720 - val_accuracy: 0.9892\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4723 - accuracy: 0.9889 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4722 - val_accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4741 - accuracy: 0.9871 - val_loss: 1.4721 - val_accuracy: 0.9891\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4708 - val_accuracy: 0.9904\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4722 - val_accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4708 - val_accuracy: 0.9902\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4730 - val_accuracy: 0.9882\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4745 - accuracy: 0.9867 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4749 - accuracy: 0.9862 - val_loss: 1.4720 - val_accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4744 - accuracy: 0.9868 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4715 - val_accuracy: 0.9895\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4726 - val_accuracy: 0.9886\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4720 - val_accuracy: 0.9892\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4722 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161392d0f08>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result22\n",
    "model03.fit(X_train22, y_train22, batch_size=128, epochs=100, verbose=1, validation_data=(X_val22, y_val22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result23\n",
    "X_train23, X_val23, y_train23, y_val23 = train_test_split(data_train, label_train, test_size=0.15, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/100\n",
      "51000/51000 [==============================] - 7s 135us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 2/100\n",
      "51000/51000 [==============================] - 7s 128us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 3/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4729 - val_accuracy: 0.9882\n",
      "Epoch 4/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4722 - val_accuracy: 0.9891\n",
      "Epoch 5/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 6/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 7/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 8/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 10/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "51000/51000 [==============================] - 6s 126us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 12/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 13/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 14/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 15/100\n",
      "51000/51000 [==============================] - 6s 126us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 16/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
      "Epoch 17/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 18/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4728 - val_accuracy: 0.9883\n",
      "Epoch 19/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4720 - val_accuracy: 0.9891\n",
      "Epoch 20/100\n",
      "51000/51000 [==============================] - 6s 125us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 21/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 22/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4722 - val_accuracy: 0.9890\n",
      "Epoch 23/100\n",
      "51000/51000 [==============================] - 7s 128us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4738 - val_accuracy: 0.9873\n",
      "Epoch 24/100\n",
      "51000/51000 [==============================] - 7s 136us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4720 - val_accuracy: 0.9891\n",
      "Epoch 25/100\n",
      "51000/51000 [==============================] - 7s 134us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4733 - val_accuracy: 0.9879\n",
      "Epoch 26/100\n",
      "51000/51000 [==============================] - 8s 149us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4729 - val_accuracy: 0.9883\n",
      "Epoch 27/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4729 - val_accuracy: 0.9882\n",
      "Epoch 28/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 29/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4726 - val_accuracy: 0.9886\n",
      "Epoch 30/100\n",
      "51000/51000 [==============================] - 8s 149us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 31/100\n",
      "51000/51000 [==============================] - 8s 152us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4732 - val_accuracy: 0.9880\n",
      "Epoch 32/100\n",
      "51000/51000 [==============================] - 8s 150us/sample - loss: 1.4739 - accuracy: 0.9873 - val_loss: 1.4719 - val_accuracy: 0.9891\n",
      "Epoch 33/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 34/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4727 - val_accuracy: 0.9884\n",
      "Epoch 35/100\n",
      "51000/51000 [==============================] - 7s 129us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 36/100\n",
      "51000/51000 [==============================] - 7s 147us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 37/100\n",
      "51000/51000 [==============================] - 8s 147us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 38/100\n",
      "51000/51000 [==============================] - 7s 147us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 39/100\n",
      "51000/51000 [==============================] - 7s 137us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4738 - val_accuracy: 0.9873\n",
      "Epoch 40/100\n",
      "51000/51000 [==============================] - 7s 135us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4721 - val_accuracy: 0.9890\n",
      "Epoch 41/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4723 - val_accuracy: 0.9889\n",
      "Epoch 42/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4726 - val_accuracy: 0.9886\n",
      "Epoch 43/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4737 - accuracy: 0.9875 - val_loss: 1.4753 - val_accuracy: 0.9859\n",
      "Epoch 44/100\n",
      "51000/51000 [==============================] - 7s 143us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 45/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 46/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 47/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 48/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 49/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 50/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4723 - val_accuracy: 0.9888\n",
      "Epoch 51/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4721 - val_accuracy: 0.9891\n",
      "Epoch 52/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4736 - accuracy: 0.9876 - val_loss: 1.4702 - val_accuracy: 0.9911\n",
      "Epoch 53/100\n",
      "51000/51000 [==============================] - 7s 143us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "51000/51000 [==============================] - 8s 148us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4723 - val_accuracy: 0.9889\n",
      "Epoch 55/100\n",
      "51000/51000 [==============================] - 7s 128us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4721 - val_accuracy: 0.9891\n",
      "Epoch 56/100\n",
      "51000/51000 [==============================] - 7s 138us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 57/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4747 - accuracy: 0.9865 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 59/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4736 - accuracy: 0.9875 - val_loss: 1.4730 - val_accuracy: 0.9881\n",
      "Epoch 60/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 61/100\n",
      "51000/51000 [==============================] - 7s 145us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4735 - val_accuracy: 0.9877\n",
      "Epoch 62/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 63/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 64/100\n",
      "51000/51000 [==============================] - 6s 127us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 65/100\n",
      "51000/51000 [==============================] - 7s 131us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 66/100\n",
      "51000/51000 [==============================] - 7s 136us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 67/100\n",
      "51000/51000 [==============================] - 8s 147us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 68/100\n",
      "51000/51000 [==============================] - 8s 148us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 69/100\n",
      "51000/51000 [==============================] - 8s 149us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "51000/51000 [==============================] - 8s 150us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 71/100\n",
      "51000/51000 [==============================] - 8s 149us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 72/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4738 - accuracy: 0.9873 - val_loss: 1.4724 - val_accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "51000/51000 [==============================] - 7s 144us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 74/100\n",
      "51000/51000 [==============================] - 7s 146us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 75/100\n",
      "51000/51000 [==============================] - 8s 152us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 76/100\n",
      "51000/51000 [==============================] - 8s 148us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 77/100\n",
      "51000/51000 [==============================] - 8s 148us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 78/100\n",
      "51000/51000 [==============================] - 8s 164us/sample - loss: 1.4732 - accuracy: 0.9879 - val_loss: 1.4735 - val_accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "51000/51000 [==============================] - 8s 155us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4726 - val_accuracy: 0.9884\n",
      "Epoch 80/100\n",
      "51000/51000 [==============================] - 7s 139us/sample - loss: 1.4740 - accuracy: 0.9872 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 81/100\n",
      "51000/51000 [==============================] - 7s 141us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 82/100\n",
      "51000/51000 [==============================] - 7s 136us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 83/100\n",
      "51000/51000 [==============================] - 7s 137us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "51000/51000 [==============================] - 7s 143us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 85/100\n",
      "51000/51000 [==============================] - 7s 143us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4730 - val_accuracy: 0.9882\n",
      "Epoch 86/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4759 - accuracy: 0.9852 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 87/100\n",
      "51000/51000 [==============================] - 7s 134us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "51000/51000 [==============================] - 7s 140us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4719 - val_accuracy: 0.9892\n",
      "Epoch 89/100\n",
      "51000/51000 [==============================] - 7s 134us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 90/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 91/100\n",
      "51000/51000 [==============================] - 7s 131us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 92/100\n",
      "51000/51000 [==============================] - 7s 129us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 93/100\n",
      "51000/51000 [==============================] - 7s 129us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 94/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4726 - accuracy: 0.9885 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 95/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 96/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 97/100\n",
      "51000/51000 [==============================] - 7s 137us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 98/100\n",
      "51000/51000 [==============================] - 7s 129us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 99/100\n",
      "51000/51000 [==============================] - 7s 129us/sample - loss: 1.4735 - accuracy: 0.9877 - val_loss: 1.4740 - val_accuracy: 0.9872\n",
      "Epoch 100/100\n",
      "51000/51000 [==============================] - 7s 130us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4710 - val_accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161397277c8>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result23\n",
    "model03.fit(X_train23, y_train23, batch_size=128, epochs=100, verbose=1, validation_data=(X_val23, y_val23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result24\n",
    "X_train24, X_val24, y_train24, y_val24 = train_test_split(data_train, label_train, test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 7s 165us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 6s 130us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4697 - val_accuracy: 0.9914\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4704 - val_accuracy: 0.9908\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 6s 131us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4723 - accuracy: 0.9889 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4719 - val_accuracy: 0.9892\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 6s 132us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 6s 140us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 7s 160us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 7s 155us/sample - loss: 1.4718 - accuracy: 0.9893 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 7s 155us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 7s 156us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4713 - accuracy: 0.9899 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 7s 157us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 7s 155us/sample - loss: 1.4718 - accuracy: 0.9893 - val_loss: 1.4706 - val_accuracy: 0.9906\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4730 - accuracy: 0.9882 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4729 - accuracy: 0.9882 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4733 - accuracy: 0.9878 - val_loss: 1.4748 - val_accuracy: 0.9863\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4731 - accuracy: 0.9880 - val_loss: 1.4725 - val_accuracy: 0.9886\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4728 - accuracy: 0.9884 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4714 - accuracy: 0.9897 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4718 - accuracy: 0.9894 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4718 - accuracy: 0.9894 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 7s 159us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 6s 142us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 6s 134us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4718 - val_accuracy: 0.9894\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 6s 134us/sample - loss: 1.4729 - accuracy: 0.9883 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 6s 140us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4725 - val_accuracy: 0.9886\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4737 - accuracy: 0.9874 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 7s 156us/sample - loss: 1.4730 - accuracy: 0.9881 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 6s 134us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4719 - accuracy: 0.9893 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 6s 134us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4727 - accuracy: 0.9884 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4725 - accuracy: 0.9887 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4718 - accuracy: 0.9894 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4721 - val_accuracy: 0.9890\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4727 - accuracy: 0.9885 - val_loss: 1.4728 - val_accuracy: 0.9883\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 6s 134us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4726 - accuracy: 0.9886 - val_loss: 1.4720 - val_accuracy: 0.9891\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4735 - accuracy: 0.9876 - val_loss: 1.4735 - val_accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4739 - accuracy: 0.9872 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4734 - accuracy: 0.9877 - val_loss: 1.4727 - val_accuracy: 0.9884\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4733 - accuracy: 0.9879 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4712 - accuracy: 0.9899 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4718 - accuracy: 0.9894 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4713 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162f6a9c588>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result24\n",
    "model03.fit(X_train24, y_train24, batch_size=128, epochs=100, verbose=1, validation_data=(X_val24, y_val24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split for result25\n",
    "X_train25, X_val25, y_train25, y_val25 = train_test_split(data_train, label_train, test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4723 - accuracy: 0.9889 - val_loss: 1.4708 - val_accuracy: 0.9904\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4725 - accuracy: 0.9887 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4711 - val_accuracy: 0.9900\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4724 - accuracy: 0.9887 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4734 - accuracy: 0.9878 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4731 - accuracy: 0.9881 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4728 - accuracy: 0.9883 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4705 - val_accuracy: 0.9907\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4718 - accuracy: 0.9893 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4714 - accuracy: 0.9897 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4717 - accuracy: 0.9895 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4714 - val_accuracy: 0.9898\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 7s 154us/sample - loss: 1.4707 - accuracy: 0.9904 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4709 - val_accuracy: 0.9902\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4712 - accuracy: 0.9900 - val_loss: 1.4699 - val_accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4714 - accuracy: 0.9898 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4714 - accuracy: 0.9897 - val_loss: 1.4701 - val_accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4722 - accuracy: 0.9890 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4718 - accuracy: 0.9894 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4717 - val_accuracy: 0.9895\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4717 - accuracy: 0.9895 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4704 - val_accuracy: 0.9907\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4708 - accuracy: 0.9903 - val_loss: 1.4700 - val_accuracy: 0.9911\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4707 - accuracy: 0.9904 - val_loss: 1.4698 - val_accuracy: 0.9913\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4709 - accuracy: 0.9902 - val_loss: 1.4699 - val_accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4702 - val_accuracy: 0.9909\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4723 - accuracy: 0.9888 - val_loss: 1.4706 - val_accuracy: 0.9907\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4702 - val_accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4722 - accuracy: 0.9889 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4713 - accuracy: 0.9899 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 7s 147us/sample - loss: 1.4713 - accuracy: 0.9899 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4725 - accuracy: 0.9886 - val_loss: 1.4706 - val_accuracy: 0.9905\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4717 - accuracy: 0.9895 - val_loss: 1.4710 - val_accuracy: 0.9902\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4729 - val_accuracy: 0.9882\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4732 - accuracy: 0.9880 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4721 - accuracy: 0.9891 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4708 - accuracy: 0.9904 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4717 - accuracy: 0.9895 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 7s 149us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4712 - accuracy: 0.9899 - val_loss: 1.4717 - val_accuracy: 0.9894\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 7s 156us/sample - loss: 1.4714 - accuracy: 0.9897 - val_loss: 1.4701 - val_accuracy: 0.9911\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 7s 153us/sample - loss: 1.4709 - accuracy: 0.9902 - val_loss: 1.4703 - val_accuracy: 0.9909\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4712 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4720 - accuracy: 0.9892 - val_loss: 1.4707 - val_accuracy: 0.9904\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4714 - accuracy: 0.9898 - val_loss: 1.4711 - val_accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4709 - val_accuracy: 0.9903\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4713 - accuracy: 0.9899 - val_loss: 1.4707 - val_accuracy: 0.9905\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4711 - accuracy: 0.9900 - val_loss: 1.4708 - val_accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 7s 150us/sample - loss: 1.4710 - accuracy: 0.9902 - val_loss: 1.4714 - val_accuracy: 0.9897\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 7s 152us/sample - loss: 1.4711 - accuracy: 0.9900 - val_loss: 1.4716 - val_accuracy: 0.9896\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 7s 156us/sample - loss: 1.4716 - accuracy: 0.9896 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 6s 143us/sample - loss: 1.4710 - accuracy: 0.9901 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 6s 135us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4713 - accuracy: 0.9898 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 6s 144us/sample - loss: 1.4714 - accuracy: 0.9898 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 7s 151us/sample - loss: 1.4716 - accuracy: 0.9895 - val_loss: 1.4712 - val_accuracy: 0.9899\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 6s 144us/sample - loss: 1.4715 - accuracy: 0.9896 - val_loss: 1.4723 - val_accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 6s 142us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4713 - val_accuracy: 0.9898\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 6s 139us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4715 - val_accuracy: 0.9897\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 6s 143us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4716 - val_accuracy: 0.9895\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 6s 142us/sample - loss: 1.4721 - accuracy: 0.9890 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 6s 138us/sample - loss: 1.4717 - accuracy: 0.9895 - val_loss: 1.4713 - val_accuracy: 0.9899\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 6s 138us/sample - loss: 1.4719 - accuracy: 0.9892 - val_loss: 1.4710 - val_accuracy: 0.9901\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 6s 140us/sample - loss: 1.4720 - accuracy: 0.9891 - val_loss: 1.4715 - val_accuracy: 0.9896\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 6s 139us/sample - loss: 1.4719 - accuracy: 0.9893 - val_loss: 1.4705 - val_accuracy: 0.9906\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 6s 136us/sample - loss: 1.4715 - accuracy: 0.9897 - val_loss: 1.4703 - val_accuracy: 0.9908\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 7s 148us/sample - loss: 1.4724 - accuracy: 0.9888 - val_loss: 1.4719 - val_accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 7s 146us/sample - loss: 1.4709 - accuracy: 0.9903 - val_loss: 1.4718 - val_accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 6s 140us/sample - loss: 1.4717 - accuracy: 0.9894 - val_loss: 1.4716 - val_accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16137a6fb88>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for result25\n",
    "model03.fit(X_train25, y_train25, batch_size=128, epochs=100, verbose=1, validation_data=(X_val25, y_val25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6201 - accuracy: 0.9303\n",
      "Epoch 2/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6175 - accuracy: 0.9312\n",
      "Epoch 3/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6199 - accuracy: 0.9298\n",
      "Epoch 4/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6194 - accuracy: 0.9294\n",
      "Epoch 5/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6181 - accuracy: 0.9308\n",
      "Epoch 6/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6182 - accuracy: 0.9309\n",
      "Epoch 7/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6171 - accuracy: 0.9301\n",
      "Epoch 8/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6175 - accuracy: 0.9295\n",
      "Epoch 9/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6152 - accuracy: 0.9321\n",
      "Epoch 10/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6160 - accuracy: 0.9296\n",
      "Epoch 11/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6153 - accuracy: 0.9305\n",
      "Epoch 12/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6157 - accuracy: 0.9305\n",
      "Epoch 13/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6167 - accuracy: 0.9299\n",
      "Epoch 14/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6153 - accuracy: 0.9306\n",
      "Epoch 15/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6149 - accuracy: 0.9302\n",
      "Epoch 16/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6152 - accuracy: 0.9301\n",
      "Epoch 17/70\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 1.6119 - accuracy: 0.9324\n",
      "Epoch 18/70\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 1.6115 - accuracy: 0.9327\n",
      "Epoch 19/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6142 - accuracy: 0.9307\n",
      "Epoch 20/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6138 - accuracy: 0.9313\n",
      "Epoch 21/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6137 - accuracy: 0.9316\n",
      "Epoch 22/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6121 - accuracy: 0.9323\n",
      "Epoch 23/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6114 - accuracy: 0.9327\n",
      "Epoch 24/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6137 - accuracy: 0.9303\n",
      "Epoch 25/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6103 - accuracy: 0.9334\n",
      "Epoch 26/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6089 - accuracy: 0.9340\n",
      "Epoch 27/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6088 - accuracy: 0.9322\n",
      "Epoch 28/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6110 - accuracy: 0.9314\n",
      "Epoch 29/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6094 - accuracy: 0.9321\n",
      "Epoch 30/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6106 - accuracy: 0.9316\n",
      "Epoch 31/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6088 - accuracy: 0.9331\n",
      "Epoch 32/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6077 - accuracy: 0.9324\n",
      "Epoch 33/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6080 - accuracy: 0.9323\n",
      "Epoch 34/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6068 - accuracy: 0.9331\n",
      "Epoch 35/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6084 - accuracy: 0.9325\n",
      "Epoch 36/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6060 - accuracy: 0.9343\n",
      "Epoch 37/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6052 - accuracy: 0.9336\n",
      "Epoch 38/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6074 - accuracy: 0.9331\n",
      "Epoch 39/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6069 - accuracy: 0.9330\n",
      "Epoch 40/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6079 - accuracy: 0.9321\n",
      "Epoch 41/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6062 - accuracy: 0.9340\n",
      "Epoch 42/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6073 - accuracy: 0.9326\n",
      "Epoch 43/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6060 - accuracy: 0.9331\n",
      "Epoch 44/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6065 - accuracy: 0.9324\n",
      "Epoch 45/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6045 - accuracy: 0.9345\n",
      "Epoch 46/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6056 - accuracy: 0.9346\n",
      "Epoch 47/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6057 - accuracy: 0.9348\n",
      "Epoch 48/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6058 - accuracy: 0.9331\n",
      "Epoch 49/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6046 - accuracy: 0.9347\n",
      "Epoch 50/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6066 - accuracy: 0.9325\n",
      "Epoch 51/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6048 - accuracy: 0.9337\n",
      "Epoch 52/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6071 - accuracy: 0.9323\n",
      "Epoch 53/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6061 - accuracy: 0.9335- loss: 1.6057 - ac\n",
      "Epoch 54/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6062 - accuracy: 0.9336\n",
      "Epoch 55/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6042 - accuracy: 0.9344\n",
      "Epoch 56/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6033 - accuracy: 0.9346\n",
      "Epoch 57/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6022 - accuracy: 0.9356\n",
      "Epoch 58/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6041 - accuracy: 0.9333\n",
      "Epoch 59/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6029 - accuracy: 0.9346\n",
      "Epoch 60/70\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 1.6035 - accuracy: 0.9344\n",
      "Epoch 61/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6039 - accuracy: 0.9334\n",
      "Epoch 62/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6017 - accuracy: 0.9347\n",
      "Epoch 63/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6022 - accuracy: 0.9345\n",
      "Epoch 64/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6010 - accuracy: 0.9362\n",
      "Epoch 65/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6023 - accuracy: 0.9343\n",
      "Epoch 66/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6024 - accuracy: 0.9346\n",
      "Epoch 67/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6018 - accuracy: 0.9347\n",
      "Epoch 68/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6021 - accuracy: 0.9346\n",
      "Epoch 69/70\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 1.6048 - accuracy: 0.9331\n",
      "Epoch 70/70\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 1.6013 - accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162f6751548>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result 14\n",
    "model04.fit(data_train, label_train, batch_size=64, epochs=70, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax layer for prediction\n",
    "probability_model = tf.keras.Sequential([model03,\n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_test = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    label_pred_test.append(np.argmax(predictions[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "result01 = np.vstack((id_test, label_pred_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 25\n",
    "resultdf = pd.DataFrame(result01)\n",
    "resultdf.columns = ['ID', 'label']\n",
    "resultdf.to_csv(\"result\" + str(i) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch: 10 => 0.89040\n",
    "# epoch: 50 => 0.88320\n",
    "# epoch: 30 => 0.89040\n",
    "# epoch: 20 => 0.89130\n",
    "# epoch: 100 => 0.88600\n",
    "\n",
    "# model6: model02, batch_size=128, epochs=25, verbose=1, validation_data=(X_val, y_val) => 0.90570\n",
    "# model7: model02, batch_size=128, epochs=25, verbose=1 => 0.91580\n",
    "# model8: model03, batch_size=128, epochs=25, verbose=1 => 0.11260 ??\n",
    "# model9: model02, batch_size=128, epochs=25, verbose=1 => 0.91130\n",
    "# model10: model02, batch_size=128, epochs=150, verbose=1 => 0.92400\n",
    "\n",
    "# model11: model03, batch_size=128, epochs=150, verbose=1 => 0.93290\n",
    "# model12: model03, batch_size=128, epochs=200, verbose=1 => 0.94050\n",
    "# model13: model02, batch_size=64, epochs=200, verbose=1 => 0.92540\n",
    "# model14: model04, batch_size=64, epochs=120, verbose=1 => 0.93160\n",
    "# model15: model03, batch_size=128, epochs=200+150+150+150+150+100+100, verbose=1 => 0.94520***\n",
    "\n",
    "# model16: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200, verbose=1 =>\n",
    "# model17: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100, verbose=1 =>\n",
    "# model18: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100, verbose=1 =>\n",
    "# model19: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100, verbose=1 =>\n",
    "# model20: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100, verbose=1 =>\n",
    "\n",
    "# model21: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100+100, verbose=1 =>\n",
    "# model22: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100+100+100, verbose=1 =>\n",
    "# model23: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100+100+100+100, verbose=1 =>\n",
    "# model24: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100+100+100+100+100, verbose=1 =>\n",
    "# model25: model03, batch_size=128, epochs=200+150+150+150+150+100+100+200+100+100+100+100+100+100+100+100+100, verbose=1 =>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
